from dotenv import load_dotenv
load_dotenv()
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

chat_model = ChatOpenAI(model="gpt-4o-mini")

st.title('ğŸ­ ì¸ê³µì§€ëŠ¥ ì‹œì¸')

content = st.text_input('ì‹œì˜ ì£¼ì œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.')

if st.button('ì‹œ ì‘ì„± ìš”ì²­í•˜ê¸°'):
    if content:
        with st.spinner('ì‹œ ì‘ì„± ì¤‘...'):
            try:
                # ìµœì‹  invoke ë°©ì‹ ì‚¬ìš©
                result = chat_model.invoke([HumanMessage(content=content + "ì— ëŒ€í•œ ì‹œë¥¼ ì¨ì¤˜")])
                
                st.markdown("### ğŸ¨ ìƒì„±ëœ ì‹œ:")
                st.markdown(f"```\n{result.content}\n```")
                
                # ì¶”ê°€ ì •ë³´ í‘œì‹œ
                with st.expander("ğŸ“Š ìƒì„± ì •ë³´"):
                    st.write(f"ëª¨ë¸: {result.response_metadata.get('model_name', 'gpt-4o-mini')}")
                    if 'token_usage' in result.response_metadata:
                        token_info = result.response_metadata['token_usage']
                        st.write(f"ì‚¬ìš©ëœ í† í°: {token_info.get('total_tokens', 'ì •ë³´ ì—†ìŒ')}")
                        
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    else:
        st.warning("âš ï¸ ì‹œì˜ ì£¼ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")