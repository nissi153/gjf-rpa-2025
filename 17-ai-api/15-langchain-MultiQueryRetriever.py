from dotenv import load_dotenv
load_dotenv()
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.chains import RetrievalQA

#Loader
loader = PyPDFLoader("./17-ai-api/resume.pdf")
pages = loader.load_and_split()

#Split
text_splitter = RecursiveCharacterTextSplitter(
    # Set a really small chunk size, just to show.
    chunk_size = 300,
    chunk_overlap  = 20,
    length_function = len,
    is_separator_regex = False,
)
texts = text_splitter.split_documents(pages)

#Embedding
embeddings_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")

# load it into Chroma
db = Chroma.from_documents(texts, embeddings_model)

#Question
question = "ì§ë¬´ ê´€ë ¨ ê²½í—˜ì€?"

try:
    # OpenAI ì‚¬ìš© ì‹œë„
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    retriver_from_llm = MultiQueryRetriever.from_llm(
        retriever=db.as_retriever(), llm=llm
    )
    docs = retriver_from_llm.get_relevant_documents(query=question)
    print(f"âœ… MultiQueryë¡œ ì°¾ì€ ë¬¸ì„œ ìˆ˜: {len(docs)}")
    
    # RetrievalQAë¡œ ë‹µë³€ ìƒì„±
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever()
    )
    result = qa_chain.run(question)
    print(f"ğŸ¤– ë‹µë³€: {result}")
    
except Exception as e:
    print(f"âŒ OpenAI API ì˜¤ë¥˜: {e}")
    print("ğŸ” ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‚¬ìš©")
    
    # ë¬´ë£Œ ëŒ€ì•ˆ: ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰
    docs = db.similarity_search(question, k=3)
    print(f"ğŸ“„ ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ë¬¸ì„œ ìˆ˜: {len(docs)}")
    
    for i, doc in enumerate(docs):
        print(f"\nğŸ“‹ ë¬¸ì„œ {i+1}:")
        print(doc.page_content[:200] + "...")

print("\nâœ… ê²€ìƒ‰ ì™„ë£Œ!")