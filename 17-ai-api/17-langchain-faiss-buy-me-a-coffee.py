from dotenv import load_dotenv
load_dotenv()
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma, FAISS
# ìƒˆë¡œìš´ íŒ¨í‚¤ì§€ ì‚¬ìš© (ê²½ê³  í•´ê²°)
try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:
    from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
import streamlit as st
import tempfile
import os
import time
from streamlit_extras.buy_me_a_coffee import button

# Buy Me a Coffee ë²„íŠ¼ ì¶”ê°€
button(username="coding_gangsa", floating=True, width=221)

st.title("ğŸ“„ ChatPDF")
st.write("PDFë¥¼ ì—…ë¡œë“œí•˜ê³  AIì™€ ëŒ€í™”í•´ë³´ì„¸ìš”! âœ¨")

# ì„¤ì • ì„¹ì…˜
with st.expander("âš™ï¸ ì„¤ì • (ì„ íƒì‚¬í•­)"):
    openai_key = st.text_input('OpenAI API Key (ê³ ê¸‰ ë‹µë³€ìš©)', type="password", 
                              help="ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ë¬´ë£Œ ê²€ìƒ‰ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤")
    
    vector_store_type = st.selectbox(
        "ë²¡í„° ì €ì¥ì†Œ ì„ íƒ:",
        ["FAISS (ë¹ ë¦„, ê¶Œì¥)", "ChromaDB (ì˜êµ¬ì €ì¥)"],
        index=0
    )
    
    embedding_model = st.selectbox(
        "ì„ë² ë”© ëª¨ë¸ ì„ íƒ:",
        [
            "sentence-transformers/all-MiniLM-L6-v2 (ë¹ ë¦„, ê¶Œì¥)",
            "sentence-transformers/all-mpnet-base-v2 (ì •í™•í•¨)"
        ],
        index=0
    )
    
    chunk_size = st.slider("ì²­í¬ í¬ê¸°", 100, 500, 200)
    chunk_overlap = st.slider("ì²­í¬ ê²¹ì¹¨", 0, 50, 10)

uploaded_file = st.file_uploader("ğŸ“ PDF íŒŒì¼ ì„ íƒ", type=['pdf'])

@st.cache_data
def process_pdf(uploaded_file):
    """PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        loader = PyPDFLoader(tmp_file.name)
        pages = loader.load_and_split()
    os.unlink(tmp_file.name)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    return pages

def create_embeddings_model(model_choice):
    """ì„ë² ë”© ëª¨ë¸ ìƒì„±"""
    if "MiniLM" in model_choice:
        model_name = "sentence-transformers/all-MiniLM-L6-v2"
    else:
        model_name = "sentence-transformers/all-mpnet-base-v2"
    
    return HuggingFaceEmbeddings(
        model_name=model_name,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

def create_vector_store(texts, embeddings, store_type):
    """ì•ˆì •ì ì¸ ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""
    try:
        if "FAISS" in store_type:
            # FAISS ì‚¬ìš© (ë¹ ë¥´ê³  ì•ˆì •ì )
            with st.spinner('ğŸš€ FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘...'):
                start_time = time.time()
                db = FAISS.from_documents(texts, embeddings)
                end_time = time.time()
                st.success(f"âœ… FAISS ìƒì„± ì™„ë£Œ! ({end_time - start_time:.2f}ì´ˆ)")
                return db
        else:
            # ChromaDB ì‚¬ìš© (ì˜êµ¬ ì €ì¥)
            with st.spinner('ğŸ’¾ ChromaDB ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘...'):
                try:
                    start_time = time.time()
                    # ë©”ëª¨ë¦¬ì—ì„œ ë¨¼ì € ìƒì„±
                    db = Chroma.from_documents(texts, embeddings)
                    end_time = time.time()
                    st.success(f"âœ… ChromaDB ìƒì„± ì™„ë£Œ! ({end_time - start_time:.2f}ì´ˆ)")
                    return db
                except Exception as chroma_error:
                    st.warning(f"âš ï¸ ChromaDB ì‹¤íŒ¨: {str(chroma_error)[:100]}...")
                    st.info("ğŸ”„ FAISSë¡œ ëŒ€ì²´ ìƒì„± ì¤‘...")
                    start_time = time.time()
                    db = FAISS.from_documents(texts, embeddings)
                    end_time = time.time()
                    st.success(f"âœ… FAISS ëŒ€ì²´ ìƒì„± ì™„ë£Œ! ({end_time - start_time:.2f}ì´ˆ)")
                    return db
                    
    except Exception as e:
        st.error(f"âŒ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

if uploaded_file:
    # PDF ì²˜ë¦¬
    with st.spinner('ğŸ“„ PDF ì²˜ë¦¬ ì¤‘...'):
        pages = process_pdf(uploaded_file)
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, 
            chunk_overlap=chunk_overlap,
            length_function=len,
            is_separator_regex=False
        )
        texts = text_splitter.split_documents(pages)
        
        st.info(f"ğŸ“Š PDF ì²˜ë¦¬ ì™„ë£Œ: {len(pages)} í˜ì´ì§€ â†’ {len(texts)} ê°œ ì²­í¬")
    
    # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    with st.spinner('ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...'):
        embeddings = create_embeddings_model(embedding_model)
        st.success("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    
    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    db = create_vector_store(texts, embeddings, vector_store_type)
    
    if db is not None:
        st.success(f"ğŸ‰ ëª¨ë“  ì„¤ì • ì™„ë£Œ! ({len(texts)}ê°œ ë¬¸ì„œ ì¡°ê°)")
        
        # ì§ˆë¬¸ ì„¹ì…˜
        st.header("ğŸ’¬ PDFì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
        question = st.text_input('ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”:', placeholder="ì˜ˆ: ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€?")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            ask_button = st.button('ğŸš€ ì§ˆë¬¸í•˜ê¸°', type="primary", use_container_width=True)
        
        with col2:
            search_only = st.button('ğŸ” ê²€ìƒ‰ë§Œ', use_container_width=True)
        
        if ask_button and question:
            with st.spinner('ğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...'):
                if openai_key:
                    # OpenAI API ì‚¬ìš© (ê³ ê¸‰ ëª¨ë“œ)
                    try:
                        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=openai_key)
                        qa_chain = RetrievalQA.from_chain_type(
                            llm, 
                            retriever=db.as_retriever(search_kwargs={"k": 3})
                        )
                        result = qa_chain.run(question)
                        
                        st.markdown("### ğŸ¤– AI ë‹µë³€:")
                        st.markdown(result)
                        
                        # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
                        with st.expander("ğŸ“š ì°¸ê³ í•œ ë¬¸ì„œë“¤"):
                            docs = db.similarity_search(question, k=3)
                            for i, doc in enumerate(docs, 1):
                                st.markdown(f"**ğŸ“„ ë¬¸ì„œ {i}:**")
                                st.text(doc.page_content[:300] + "...")
                                st.divider()
                                
                    except Exception as e:
                        st.error(f"âŒ OpenAI API ì˜¤ë¥˜: {e}")
                        st.info("ğŸ” ë¬´ë£Œ ê²€ìƒ‰ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
                        docs = db.similarity_search(question, k=3)
                        for i, doc in enumerate(docs, 1):
                            with st.expander(f"ğŸ“„ ê´€ë ¨ ë¬¸ì„œ {i}"):
                                st.write(doc.page_content)
                else:
                    # ë¬´ë£Œ ê²€ìƒ‰ ëª¨ë“œ
                    st.info("ğŸ†“ ë¬´ë£Œ ê²€ìƒ‰ ëª¨ë“œ (OpenAI API í‚¤ ì—†ìŒ)")
                    docs = db.similarity_search(question, k=3)
                    for i, doc in enumerate(docs, 1):
                        with st.expander(f"ğŸ“„ ê´€ë ¨ ë¬¸ì„œ {i}"):
                            st.write(doc.page_content)
        
        elif search_only and question:
            with st.spinner('ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...'):
                docs = db.similarity_search(question, k=5)
                st.markdown("### ğŸ” ê²€ìƒ‰ ê²°ê³¼:")
                
                for i, doc in enumerate(docs, 1):
                    with st.expander(f"ğŸ“„ ê´€ë ¨ ë¬¸ì„œ {i}", expanded=i<=2):
                        st.write(doc.page_content)
                        if hasattr(doc, 'metadata') and doc.metadata:
                            st.caption(f"ì¶œì²˜: {doc.metadata}")
        
        elif (ask_button or search_only) and not question:
            st.warning("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            
        # ìƒ˜í”Œ ì§ˆë¬¸ ì œê³µ
        st.markdown("### ğŸ’¡ ìƒ˜í”Œ ì§ˆë¬¸:")
        sample_questions = [
            "ì´ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”",
            "í•µì‹¬ í‚¤ì›Œë“œë‚˜ ê°œë…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì¤‘ìš”í•œ ë‚ ì§œë‚˜ ìˆ«ìê°€ ìˆë‚˜ìš”?",
            "ê²°ë¡ ì´ë‚˜ ìš”ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ]
        
        for i, sample in enumerate(sample_questions):
            if st.button(f"ğŸ“ {sample}", key=f"sample_{i}"):
                st.text_input('ğŸ’¬ PDFì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:', value=sample, key="auto_question")
    
    else:
        st.error("âŒ ë²¡í„° ì €ì¥ì†Œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ì •ì„ ì‹œë„í•´ë³´ì„¸ìš”.")

else:
    st.info("ğŸ‘† PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì‹œì‘ë©ë‹ˆë‹¤!")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´"):
        st.markdown("""
        **1ë‹¨ê³„:** PDF íŒŒì¼ ì—…ë¡œë“œ
        - ì„¤ì •ì—ì„œ ë²¡í„° ì €ì¥ì†Œì™€ ì„ë² ë”© ëª¨ë¸ ì„ íƒ
        - FAISS (ë¹ ë¦„) ë˜ëŠ” ChromaDB (ì˜êµ¬ì €ì¥) ì„ íƒ
        
        **2ë‹¨ê³„:** ì§ˆë¬¸ ì…ë ¥
        - ìì—°ì–´ë¡œ ì§ˆë¬¸ ì‘ì„±
        - ìƒ˜í”Œ ì§ˆë¬¸ ë²„íŠ¼ í™œìš©
        
        **3ë‹¨ê³„:** ë‹µë³€ í™•ì¸
        - ğŸš€ ì§ˆë¬¸í•˜ê¸°: AIê°€ ë‹µë³€ ìƒì„± (OpenAI API í•„ìš”)
        - ğŸ” ê²€ìƒ‰ë§Œ: ê´€ë ¨ ë¬¸ì„œë§Œ í‘œì‹œ (ë¬´ë£Œ)
        
        **ëª¨ë“œ:**
        - ğŸ†“ **ë¬´ë£Œ ëª¨ë“œ**: OpenAI API ì—†ì´ë„ ë¬¸ì„œ ê²€ìƒ‰ ê°€ëŠ¥
        - ğŸ¤– **ê³ ê¸‰ ëª¨ë“œ**: OpenAI APIë¡œ ì •í™•í•œ ë‹µë³€ ìƒì„±
        
        **íŒ:**
        - ì²­í¬ í¬ê¸°ê°€ ì‘ì„ìˆ˜ë¡ ë” ì •í™•í•œ ê²€ìƒ‰
        - FAISSê°€ ë” ë¹ ë¥´ê³  ì•ˆì •ì 
        - MiniLM ëª¨ë¸ì´ ë” ë¹ ë¦„
        - â˜• ì˜¤ë¥¸ìª½ í•˜ë‹¨ ë²„íŠ¼ìœ¼ë¡œ ê°œë°œì ì‘ì›í•˜ê¸°
        """)
    
    st.markdown("""
    ### ğŸŒŸ ê¸°ëŠ¥ ì†Œê°œ:
    - ğŸ“„ **PDF ë¶„ì„**: ë¬¸ì„œë¥¼ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
    - ğŸ†“ **ë¬´ë£Œ ëª¨ë“œ**: OpenAI API ì—†ì´ë„ ë¬¸ì„œ ê²€ìƒ‰ ê°€ëŠ¥
    - ğŸ¤– **ê³ ê¸‰ ëª¨ë“œ**: OpenAI APIë¡œ ì •í™•í•œ ë‹µë³€ ìƒì„±
    - âš™ï¸ **ê³ ê¸‰ ì„¤ì •**: ë²¡í„° ì €ì¥ì†Œ, ì„ë² ë”© ëª¨ë¸, ì²­í¬ í¬ê¸° ì¡°ì •
    - â˜• **í›„ì›**: ì˜¤ë¥¸ìª½ í•˜ë‹¨ ë²„íŠ¼ìœ¼ë¡œ ê°œë°œì ì‘ì›í•˜ê¸°
    """) 